# Part 2. Just-in-time job submission

## 2.
The current setup will require waiting for all the `rplraw` files in an array to be created before the `rpllfp` and `rplhighpass` files can be created, and before the spike sorting can start processing the highpass files. This is also inefficient, as processing on each of the rplraw files should be able to start once they are created. 

## 3.
Make a copy of the `rs1-slurm.sh` script, and name it `rs1a-slurm.sh`. Modify the `RPLSplit` function in `rs1a-slurm.sh` to make use of the option to submit a slurm script after each `rplraw` file has been created:

```shell
DPT.objects.processDirs(dirs=None, objtype=pyh.RPLSplit, channel=[*range(1,33)], SkipHPC=False, HPCScriptsDir = '/data/src/PyHipp/', SkipLFP=False, SkipHighPass=False, SkipSort=False);
```

With `SkipHPC=False` and `SkipLFP=False`, it will look in the `HPCScriptsDir` directory for a script named `rpllfp-slurm.sh`, and submit it from the channel directory once the `rplraw` file is created. This script will create the `rpllfp` files.

Similarly, with `SkipHPC=False`, `SkipHighPass=False`, and `SkipSort=False`, it will submit a script named `rplhighpass-sort-slurm.sh` from the channel directory once the `rplraw` file is created. This script will create the `rplhighpass` files, and perform the spike sorting. So the Python command to split the files, and to generate the RPLLFP and RPLHighPass objects, can be shortened to:

```shell
python -u -c "import PyHipp as pyh; \
import DataProcessingTools as DPT; \
import time; \
import os; \
t0 = time.time(); \
print(time.localtime()); \
DPT.objects.processDirs(dirs=None, objtype=pyh.RPLSplit, channel=[*range(1,33)], SkipHPC=False, HPCScriptsDir = '/data/src/PyHipp/', SkipLFP=False, SkipHighPass=False, SkipSort=False); \
print(time.localtime()); \
print(time.time()-t0);"
```

> <p class="note"> Note
>
> Remember to also change the name of the job and output files.

## 4.
Do the same for the other three `rs?a-slurm.sh` scripts.

## 5.
However, the spike sorting requires the `highpass` files from both `sessioneye` and `session01` to be created first, and should be called only from the `session01` directory. The scripts above will start the spike sorting once the `highpass` files in `session01` are created, and before the `highpass` files in `sessioneye` have been created. It will also start the spike sorting a second time once the `highpass` files in `sessioneye` are created. So we will want to generate the `highpass` files in one of the two session directories first without calling the spike sorting, and then call spike sorting only after the second set of `highpass` files have been created. We will choose to process the `sessioneye` files first as they are much smaller, so you should create another slurm script `rse-slurm.sh` that will call `rplsplit` for just the data in `sessioneye`. Since the `sessioneye` files are fairly small, we can do this with just one job like this (save this into `rse-slurm.sh`):

```shell
python -u -c "import PyHipp as pyh; \
import time; \
import os; \
t0 = time.time(); \
print(time.localtime()); \
os.chdir('sessioneye'); \
pyh.RPLSplit(SkipLFP=False, SkipHighPass=False); \
print(time.localtime()); \
print(time.time()-t0);"
```

Since the file sizes are small, you can change `cpus-per-task` back to `1` in this slurm script.

## 6.
In addition, create the scripts `rpllfp-slurm.sh` and `rplhighpass-sort-slurm.sh` so they can be used by `RPLSplit` to submit jobs from the channel directory once the `rplraw` files are created:

```bash
python -u -c "import PyHipp as pyh; \
import time; \
pyh.RPLLFP(saveLevel=1); \
print(time.localtime());"

python -u -c "import PyHipp as pyh; \
import time; \
pyh.RPLHighPass(saveLevel=1); \
from PyHipp import mountain_batch; \
mountain_batch.mountain_batch(); \
from PyHipp import export_mountain_cells; \
export_mountain_cells.export_mountain_cells(); \
print(time.localtime());"
```

Since there will be a lot of these jobs, you will want to omit the SNS message sent at the end of the job.

In this setup, the `rs?a` jobs will take a lot less time as they only submit the slurm scripts once the rplraw files are created, and do not actually need to generate the low-pass, high-pass, and spike sorting files. So, in order to compute how much time the entire pipeline took, we will use the start time of the `rplparallel` job (since it is the first job submitted), and the end time of the last job, which will likely be a `rplhighpass-sort` job. In order to be safe, we will print out the end time for both the `rpllfp` and `rplhighpass-sort` jobs.

As the `rpllfp-slurm.sh` and `rplhighpass-sort-slurm.sh` scripts will be working off the `rplraw` files, which are much smaller than the `.ns5` files, you will not need more memory than is normally available to each vCPU, so you can use `cpus-per-task=1` for these scripts. Remember to also change the name of the job and output files. 

## 7.
Modify the `pipe2.sh` script (and save it as `pipe2a.sh`) to call `rse-slurm.sh` before calling the `rs?a-slurm.sh` scripts, and have the `rs?a` jobs depend on the `rse` job:

```bash
# second job - no dependencies, called from the day directory
jid2=$(sbatch /data/src/PyHipp/rse-slurm.sh)

# third set of jobs - depends on rse-slurm.sh, called from the day directory
jid3=$(sbatch --dependency=afterok:${jid2##* } /data/src/PyHipp/rs1a-slurm.sh)
jid4=$(sbatch --dependency=afterok:${jid2##* } /data/src/PyHipp/rs2a-slurm.sh)
jid5=$(sbatch --dependency=afterok:${jid2##* } /data/src/PyHipp/rs3a-slurm.sh)
jid6=$(sbatch --dependency=afterok:${jid2##* } /data/src/PyHipp/rs4a-slurm.sh)
```

## 8.
You can add your new scripts to your GitHub repository:

```shell
(env1) [ec2-user@ip-10-0-5-43 PyHipp] $ git add rs?a-slurm.sh rse-slurm.sh rpllfp-slurm.sh rplhighpass-sort-slurm.sh pipe2a.sh

(env1) [ec2-user@ip-10-0-5-43 PyHipp] $ git commit
```

You can push all the changes to your repository by doing:

```shell
(env1) [ec2-user@ip-10-0-5-43 PyHipp] $ git push
```

You will then be prompted to enter your GitHub username and token again. 
