# Part 5. Checking and resubmitting jobs

## 25.
Once you receive the notification that the snapshot has been completed, remember to run the `pcluster delete-cluster …` command to remove `MyCluster01` from the list of clusters. You can then create a new cluster to compute the time taken to process the files. You might want to use the `pcluster describe-cluster …` command to wait for the `delete-cluster` to be done before you create another cluster named `MyCluster01` to avoid having to modify the cluster name in the `ec2snapshot.sh` script.

## 26.
Check the output using your `checkfiles2.sh` script. In order to compute the time taken properly, you will need to get the start time for the `rplparallel` job (since it is the first job that is submitted), and the end time of the last `rpllfp` or `rplhighpass-sort` job. You can get the former from the output of `checkfiles2.sh`, but for the latter, you will need to do the following (the “-or” argument for the find function allows you to find files in the `session01` directory that match either of the name patterns that you used to name the output files):

```shell
(env1) [ec2-user@ip-10-0-5-43 20181105] $ find session01 -name "hps*out" -or -name "lfp*out" | xargs tail -n 1 | sort
```

which should give you something like:

```shell
time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=5, tm_min=8, tm_sec=6, tm_wday=2, tm_yday=281, tm_isdst=0)
time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=6, tm_min=23, tm_sec=10, tm_wday=2, tm_yday=281, tm_isdst=0)
time.struct_time(tm_year=2020, tm_mon=10, tm_mday=7, tm_hour=6, tm_min=23, tm_sec=6, tm_wday=2, tm_yday=281, tm_isdst=0)
```

The end times will be sorted by alphabetical order and not numerical order, so you might need to scroll up to make sure you find the latest timestamp. 

> <p class="task"> Task
>
> Include the first five timestamps and the last five timestamps of the output above, and compute the total time taken in your lab report.

## 27.
If for some reason some of the jobs failed, you can do the following to re-submit those jobs. Since the bulk of the jobs are being called from the channel directory, we will first create a list of channels:

```shell
(env1) [ec2-user@ip-10-0-5-43 20181105] $ find . -name "channel*" | grep -v -e eye -e mountain | sort > chs.txt
```

This command is similar to the one we used in Step 35 in Lab 2 except we are now sorting the output before saving it into a file named `chs.txt` by using the `>` function.

## 28.
Next, we will create a list of channels that already have the appropriate files generated. For instance, if we are looking to generate `rplhighpass` files for certain channels, we can find the channels that already have `rplhighpass` files:

```shell
(env1) [ec2-user@ip-10-0-5-43 20181105] $ find . -name "rplhighpass*hkl" | grep -v -e eye | sort | cut -d "/" -f 1-4 > hps.txt
```

The cut command allows us to print selected fields that are separated by the delimiter character specified by the `-d` option, in this case `/`. You can check what each of the commands do by removing the other commands. 

You can use a similar command to find the channels that successfully completed any jobs by looking for their corresponding output files. 

## 29.
Now that we have a list of all channels, and a list of channels with `rplhighpass` files, we can find the channels that do not have `rplhighpass` files by doing:

```shell
(env1) [ec2-user@ip-10-0-5-43 20181105] $ comm -23 chs.txt hps.txt
```
The `comm` command returns lines that are found only in the first file in the first column, lines that are found in the second file in the second column, and lines that are common to both files in the third column. By specify `-23`, you can suppress the second and third columns, which will return just the lines that are found only in the first file, which in this case will correspond to the channel directories that are missing the `rplhighpass` file.

If you are searching for the channels that did not successfully complete the spike sorting (by looking for `firings.mda` files), you need to make some modifications to the commands above. Since `firings.mda` files are stored in the `mountains` folder, they cannot be directly compared against `chs.txt`. You need to use the `cut` command to extract only the `channel???` strings, save them into separate files. You can then use the `comm` function to look for missing channels, and then use a for-loop to find the appropriate path to each missing `channel???` in `chs.txt`. Finally, save the output into a txt file.

> <p class="note"> Note
>
> You may want to use the `grep` function to help in searching for the missing channel

## 30.
You can now re-run the `rplhighpass-sort-slurm.sh` script (or whichever script or command you need to run) by doing:

```shell
(env1) [ec2-user@ip-10-0-5-43 20181105] $ cwd=`pwd`; for i in `comm -23 chs.txt hps.txt`; do echo $i; cd $i; sbatch /data/src/PyHipp/rplhighpass-sort-slurm.sh; cd $cwd; done
```

The command above saves the current directory into a shell variable named `cwd`, and then uses a for-loop to iterate over the directories returned by the `comm` function above. In each directory, it submits a slurm job to process the data in that directory, before changing directories back to the initial directory (saved in the `cwd` variable), and continuing with the next step of the for-loop.


If you have saved the list of directories in a file, you can replace the command `comm -23 chs.txt hps.txt` with `cat missing-sort-chs.txt`.

> <p class="note"> Note
>
> Optional: You can also create and use a `sort-slurm.sh` script above (instead of the `rplhighpass-sort-slurm.sh` script) that just reruns the spike sorting if the highpass files already exist, and only the spike sorting files are missing.

> <p class="task"> Task
>
> Include the output of `checkfiles.sh` showing the correct number of output files in your lab report.


